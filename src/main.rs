mod api;
mod core;
mod infra;
mod models;
mod service;

use axum::{routing::{get, post,delete}, Router};
use std::net::SocketAddr;
use std::sync::Arc;
use tokio::sync::RwLock;
use tower_http::cors::{Any, CorsLayer};
use tower_http::trace::TraceLayer; 
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt}; 

use sqlx::Row;

use crate::api::chat::chat_query;
use crate::api::mapping::{
    list_mappings, register_data_source, save_mapping, list_data_sources, 
    get_metadata_tables, get_metadata_columns, sync_dimension_values, export_ontology_ttl,
    delete_mapping
};
use crate::core::fst_engine::FstEngine;
use crate::core::inference::SemanticInferenceEngine;
use crate::infra::db_external::PoolManager;
use crate::models::schema::FullSemanticNode;

pub mod ax_state {
    use super::*;
    pub struct AppState {
        pub db: sqlx::PgPool,
        pub fst: RwLock<FstEngine>,
        pub pool_manager: PoolManager,
        pub engine: RwLock<SemanticInferenceEngine>, // ã€æ ¸å¿ƒã€‘å°†æ¨ç†å¼•æ“å•ä¾‹åŒ–
    }
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // 1. åŠ è½½é…ç½®ä¸åˆå§‹åŒ–å†…éƒ¨æ•°æ®åº“
    dotenvy::dotenv().ok();

    // --- 1. åˆå§‹åŒ– tracing æ—¥å¿— ---
    tracing_subscriber::registry()
        .with(tracing_subscriber::EnvFilter::try_from_default_env().unwrap_or_else(|_| "sse_backend=debug,tower_http=debug".into()))
        .with(tracing_subscriber::fmt::layer())
        .init();

    tracing::info!("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– SSE ä¼ä¸šçº§è¯­ä¹‰æœåŠ¡å™¨...");

    let db = infra::db_internal::init_db().await;

    // 2. æ ¸å¿ƒï¼šå¯åŠ¨æ—¶åŠ è½½å…¨é‡è¯­ä¹‰èŠ‚ç‚¹ (åˆå§‹åŒ– FST)
    // è¿™é‡Œçš„ SQL å¿…é¡»ä¸ mapping.rs ä¸­çš„ list é€»è¾‘ä¿æŒé«˜åº¦ä¸€è‡´
    let mappings_res = sqlx::query_as::<sqlx::Postgres, FullSemanticNode>(
        r#"
        SELECT n.id, n.node_key, n.label, n.node_role, d.source_id, d.target_table, d.sql_expression, 
               d.default_constraints, d.alias_names, d.default_agg, n.dataset_id,
               COALESCE(array_agg(r.dimension_node_id) FILTER (WHERE r.dimension_node_id IS NOT NULL), '{}') as supported_dimension_ids
        FROM ontology_nodes n 
        JOIN semantic_definitions d ON n.id = d.node_id
        LEFT JOIN metric_dimension_rels r ON n.id = r.metric_node_id
        GROUP BY n.id, n.node_key, n.label, n.node_role, d.source_id, d.target_table, d.sql_expression, d.default_constraints, d.alias_names, d.default_agg, n.dataset_id
        "#
    )
    .fetch_all(&db)
    .await;

    let nodes = match mappings_res {
        Ok(n) => {
            tracing::info!("âœ… [Init] æˆåŠŸåŠ è½½ {} ä¸ªè¯­ä¹‰èŠ‚ç‚¹åˆ°å†…å­˜ç´¢å¼•", n.len());
            n
        },
        Err(e) => {
            tracing::error!("âŒ [Init] æ— æ³•åŠ è½½è¯­ä¹‰èŠ‚ç‚¹: {:?}", e);
            Vec::new()
        }
    };

    // 3. æ„å»º FST å¼•æ“
    let fst_engine = FstEngine::build(&nodes)?;

    // åˆå§‹åŒ–æ¨ç†å¼•æ“å¹¶åŒæ­¥ä¸šåŠ¡è¯å…¸
    let mut inference_engine = SemanticInferenceEngine::new();
    
    // æå–æ‰€æœ‰å¯èƒ½çš„ä¸šåŠ¡è¯æ±‡ï¼ˆæ ‡ç­¾ã€åˆ«åã€ç å€¼ï¼‰
    let mut words = nodes.iter().flat_map(|n| {
        let mut v = vec![n.label.clone()];
        v.extend(n.alias_names.clone());
        v
    }).collect::<Vec<String>>();

    // æå– A-Box ç å€¼
    let codes = sqlx::query("SELECT value_label FROM dimension_values").fetch_all(&db).await?;
    words.extend(codes.into_iter().map(|r| r.get::<String, _>(0)));
    
    inference_engine.refresh_custom_words(words);
    
    // 4. åˆå§‹åŒ–å…¨å±€çŠ¶æ€
    let state = Arc::new(ax_state::AppState {
        db,
        fst: RwLock::new(fst_engine),
        pool_manager: PoolManager::new(),
        engine: RwLock::new(inference_engine),
    });

    // 5. é…ç½®ä¸­é—´ä»¶ä¸è·¯ç”±
    let cors = CorsLayer::new()
        .allow_origin(Any)
        .allow_methods(Any)
        .allow_headers(Any);

    let app = Router::new()
        // è¯­ä¹‰å»ºæ¨¡æ¥å£
        .route("/api/mappings", get(list_mappings))
        .route("/api/mapping", post(save_mapping))
        .route("/api/mapping/{id}", delete(delete_mapping))
        .route("/api/ontology/export", get(export_ontology_ttl))
        
        // å…ƒæ•°æ®ä¸åŒæ­¥
        .route("/api/metadata/tables", get(get_metadata_tables))
        .route("/api/metadata/columns", get(get_metadata_columns))
        .route("/api/sync-values/{id}", post(sync_dimension_values))
        
        // æ•°æ®æºç®¡ç†
        .route("/api/datasource", post(register_data_source))
        .route("/api/datasources", get(list_data_sources))
        
        // é—®æ•°å¯¹è¯ (æ ¸å¿ƒ)
        .route("/api/chat", post(chat_query))
        
        .with_state(state)
        .layer(cors)
        .layer(TraceLayer::new_for_http());

    // 6. å¯åŠ¨æœåŠ¡
    let addr = SocketAddr::from(([0, 0, 0, 0], 3000));
    tracing::info!("ğŸ”¥ SSE Enterprise Backend is running on http://{}", addr);
    
    let listener = tokio::net::TcpListener::bind(addr).await?;
    axum::serve(listener, app).await?;
    
    Ok(())
}